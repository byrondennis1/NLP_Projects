{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic Comment Classification Challenge",
      "provenance": [],
      "collapsed_sections": [
        "oUkHrG4UQQqP"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byrondennis1/NLP_Projects/blob/master/Toxic_Comment_Classification_Challenge_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpCuVUKBOu8J",
        "colab_type": "text"
      },
      "source": [
        "# 1st Place Results in the Kaggle Toxic Comment Classification Challenge\n",
        "\n",
        "**Using the HuggingFace library I was able to fine tune bert on the competition data and obtain 1st place results.**  \n",
        "\n",
        "- The results are really a testament to the power of BERT and the improvements made in NLP since the competition which ended 2 years ago.  as the process was fairly straightforward and I did not spend any time tuning parameters.  \n",
        "\n",
        "- Another point to mention is that I fine-tuned the classification layer and then did additional training on the entire network, but there are still methodologies that can be implemented to improve performance such more strategic layer unfreezing, discriminative layer training.  \n",
        "\n",
        "- I also did not attempt to optimize the learning rate, which would be worth doing even to speed up training time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1zKRmCE494W",
        "colab_type": "text"
      },
      "source": [
        "**About the competition.**\n",
        "\n",
        "In this competition, you’re challenged to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models. You’ll be using a dataset of comments from Wikipedia’s talk page edits. Improvements to the current model will hopefully help online discussion become more productive and respectful.\n",
        "\n",
        "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUkHrG4UQQqP",
        "colab_type": "text"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPUUHrBmS4Xz",
        "colab_type": "code",
        "outputId": "b5b06900-bde7-4e7d-d2a3-936949e47c75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
            "\r\u001b[K     |▊                               | 10kB 25.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 3.9MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 112kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 122kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 174kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 194kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 225kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 245kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 296kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 317kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 337kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 348kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 368kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 389kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 399kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 409kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 440kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 450kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 19.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 34.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.47)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=5aad0c44c4fec9ef754b8c9293cb7163a2e93bf01fe154b7cdad3cc5c0e4be66\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 transformers-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDoLS4jOQg-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "535b4816-26a6-47b7-fe3a-483ebd017b57"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from transformers import (\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    BertConfig,\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7vCVUMbXiZu",
        "colab_type": "text"
      },
      "source": [
        "## Import Dataset and Convert to Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNqogOYYXOA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv.zip')\n",
        "test = pd.read_csv('test.csv.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vat1S3ExGwXY",
        "colab_type": "code",
        "outputId": "42d96787-2078-4bb6-f7b4-db79225480a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"train shape: \", train.shape)\n",
        "print(\"test shape:\", test.shape)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape:  (159571, 8)\n",
            "test shape: (153164, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEeeVhPRc8cA",
        "colab_type": "code",
        "outputId": "0f9f66af-e8e9-436e-a08f-f099b32bdbd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "train.head(2)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUP6ktmcwZZX",
        "colab_type": "text"
      },
      "source": [
        "**Create single column with all labels and remove new line characters (\\n)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNi92_iDpBBK",
        "colab_type": "code",
        "outputId": "0b8beda5-37e3-40f9-abda-3e0f0e13619b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "# create labels\n",
        "labels = train.iloc[:,2:8].values\n",
        "\n",
        "# clean text\n",
        "train['text'] = train.comment_text.replace('\\n', ' ', regex=True)\n",
        "test['text'] = test.comment_text.replace('\\n', ' ', regex=True)\n",
        "\n",
        "train.head(2)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Explanation Why the edits made under my userna...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ...                                               text\n",
              "0  0000997932d777bf  ...  Explanation Why the edits made under my userna...\n",
              "1  000103f0d9cfb60f  ...  D'aww! He matches this background colour I'm s...\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbN4Fv5MxfEL",
        "colab_type": "text"
      },
      "source": [
        "**Get Tokens using BertTokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By96_srwbLHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW5QW2IivJv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['encoded'] = train.text.apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=100, pad_to_max_length=True)))\n",
        "test['encoded'] = test.text.apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=100, pad_to_max_length=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy6_wVdUZGns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create attention masks that identify padding\n",
        "\n",
        "def attn_msk(df, col):\n",
        "\n",
        "  attention_masks = []\n",
        "\n",
        "  for sent in df[col]:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks.append(att_mask)\n",
        "\n",
        "  return attention_masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljjTZ_6Jeht7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_msks = attn_msk(train, 'encoded')\n",
        "tst_msks = attn_msk(test, 'encoded')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs6D-NI9ZxPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert data lists to tensors\n",
        "trn_inputs, trn_masks, trn_targets = torch.tensor(train.encoded), torch.tensor(trn_msks), torch.tensor(labels)\n",
        "tst_inputs, tst_masks = torch.tensor(test.encoded), torch.tensor(tst_msks)\n",
        "\n",
        "# convert targets to float / BCELoss expects float\n",
        "trn_targets = trn_targets.float() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBTK74EaKwtY",
        "colab_type": "text"
      },
      "source": [
        "## Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Ja35b_KueE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# Create the train/valid dataloaders\n",
        "trn_dataset = TensorDataset(trn_inputs, trn_masks, trn_targets)\n",
        "trn, vld = random_split(trn_dataset, [140000, 19571])\n",
        "\n",
        "train_dataloader = DataLoader(trn, shuffle=True, batch_size=batch_size)\n",
        "valid_dataloader = DataLoader(vld, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "# prepare test data\n",
        "tst_dataset = TensorDataset(tst_inputs, tst_masks)\n",
        "test_dataloader = DataLoader(tst_dataset, shuffle=False, batch_size=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cG5MtReW2Ex",
        "colab_type": "text"
      },
      "source": [
        "## Finetune Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek_rCEsu0L45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqJBzNpZHB-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', \n",
        "                                                      output_hidden_states = False,\n",
        "                                                      output_attentions = False, \n",
        "                                                      num_labels=6)\n",
        "\n",
        "# freeze all layers except final classification layer\n",
        "for param in model.bert.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# move model to gpu\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = AdamW(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INsVWWHHW8C5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training loop \n",
        "\n",
        "def training_loop(epochs):\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "      # get the inputs; data is a list of [inputs, labels]\n",
        "      inputs, attention_masks, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # forward + backward + optimize\n",
        "      outputs = model(inputs, attention_mask=attention_masks)\n",
        "      loss = criterion(torch.sigmoid(outputs[0]), labels)  # applied sigmoid to change prediction output to 1 or 0\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # print statistics\n",
        "      running_loss += loss.item()\n",
        "      if i % 500 == 499:    # print every 500 mini-batches\n",
        "          print('[%d, %5d] loss: %.3f' %\n",
        "                (epoch + 1, i + 1, running_loss / 500))\n",
        "          running_loss = 0.0\n",
        "\n",
        "  print('Finished Training')  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Rt9ATZCRRvh",
        "colab_type": "code",
        "outputId": "2f51db21-97cf-4c58-bba2-59632de4f250",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "# train classification layer of model\n",
        "\n",
        "training_loop(1)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 0.136\n",
            "[1,  1000] loss: 0.108\n",
            "[1,  1500] loss: 0.104\n",
            "[1,  2000] loss: 0.100\n",
            "[1,  2500] loss: 0.098\n",
            "[1,  3000] loss: 0.091\n",
            "[1,  3500] loss: 0.097\n",
            "[1,  4000] loss: 0.088\n",
            "[1,  4500] loss: 0.097\n",
            "[1,  5000] loss: 0.088\n",
            "[1,  5500] loss: 0.083\n",
            "[1,  6000] loss: 0.088\n",
            "[1,  6500] loss: 0.091\n",
            "[1,  7000] loss: 0.083\n",
            "[1,  7500] loss: 0.087\n",
            "[1,  8000] loss: 0.091\n",
            "[1,  8500] loss: 0.079\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mLbPt85MaaQx",
        "colab": {}
      },
      "source": [
        "# unfreeze additional layers and train another epoch\n",
        "\n",
        "for param in model.bert.parameters():\n",
        "   param.requires_grad = True\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSCFxUNMQc_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "64f5bf43-2d8e-48ca-bf65-370cb617df8b"
      },
      "source": [
        "training_loop(1)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   500] loss: 0.064\n",
            "[1,  1000] loss: 0.050\n",
            "[1,  1500] loss: 0.050\n",
            "[1,  2000] loss: 0.046\n",
            "[1,  2500] loss: 0.048\n",
            "[1,  3000] loss: 0.043\n",
            "[1,  3500] loss: 0.044\n",
            "[1,  4000] loss: 0.044\n",
            "[1,  4500] loss: 0.042\n",
            "[1,  5000] loss: 0.043\n",
            "[1,  5500] loss: 0.040\n",
            "[1,  6000] loss: 0.043\n",
            "[1,  6500] loss: 0.041\n",
            "[1,  7000] loss: 0.039\n",
            "[1,  7500] loss: 0.044\n",
            "[1,  8000] loss: 0.042\n",
            "[1,  8500] loss: 0.040\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6xkRSzK_nQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save Model\n",
        "# torch.save(model.state_dict(), 'toxic_comment_model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gNKMmkc_H5r",
        "colab_type": "text"
      },
      "source": [
        "## Evalutate Model Using Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekt79i_JAD_9",
        "colab_type": "code",
        "outputId": "64dedbb7-38f2-4180-d633-dc839408396a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(valid_dataloader, 0):\n",
        "    # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, attention_masks, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
        "    outputs = model(inputs, attention_mask=attention_masks)\n",
        "    loss = criterion(torch.sigmoid(outputs[0]), labels)\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "\n",
        "print(running_loss)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54.30625113845417\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtwhwSWkD4Fa",
        "colab_type": "code",
        "outputId": "d44c966c-fe23-40f2-fe1a-16d973e0740c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# loss divided by len(valid)/batch_size \n",
        "\n",
        "running_loss / 1223"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.044404130121385256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1B5LtYJEMqi",
        "colab_type": "text"
      },
      "source": [
        "## Predict on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGQnsv4uRmZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions=[]\n",
        "\n",
        "for i, data in enumerate(test_dataloader, 0):\n",
        "  # get the inputs; data is a list of [inputs, labels]\n",
        "  inputs, attention_masks = data[0].to(device), data[1].to(device)\n",
        "  # get predictions\n",
        "  with torch.no_grad():\n",
        "    outputs = model(inputs, attention_mask=attention_masks)\n",
        "    outputs = torch.sigmoid(outputs[0])\n",
        "  predictions.append(outputs[0].detach().cpu().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqb5mh8Rgz5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add predictions to test file\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "columns=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "preds = np.vstack(predictions)\n",
        "submission = pd.DataFrame(preds, columns=columns, index=test.id)\n",
        "submission.reset_index(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBWDBrnc1RYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zdmIozx0_y0",
        "colab_type": "text"
      },
      "source": [
        "## The submission resulted in a score of **0.98334**! \n",
        "\n",
        "This would have been better than the 1st place results on the private leaderboard (0.98856).  Top public leaderboard score was 0.98901."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESsXheEC10q0",
        "colab_type": "text"
      },
      "source": [
        "The BERT model makes it easy to get great results, but the predictions took a long time to run.  Perhaps there is a more efficient way to load the data or run calculate predictions.  I could also reduce the maximium length of the tokens and see if I can maintain good accuracy and speed up processing."
      ]
    }
  ]
}